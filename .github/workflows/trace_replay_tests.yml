name: Trace Replay Tests

on:
  push:
  pull_request:

jobs:
  trace-replay:
    name: Trace Replay & Coverage
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11', '3.12', '3.13']

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e '.[test]'  # Assuming [test] extras in pyproject.toml for pytest, etc.

      - name: Prepare output directory
        run: mkdir -p test_output

      - name: Validate trace files
        run: |
          echo "üîç Validating trace files before running tests..."
          python -c "
          import os
          import sys
          from pathlib import Path

          trace_dir = Path('tests/data/traces')
          if not trace_dir.exists():
              print(f'‚ùå Trace directory not found: {trace_dir}')
              sys.exit(1)

          trace_files = list(trace_dir.glob('*.trc'))
          if not trace_files:
              print(f'‚ùå No trace files found in {trace_dir}')
              sys.exit(1)

          print(f'‚úÖ Found {len(trace_files)} trace files:')
          for tf in trace_files:
              size = tf.stat().st_size
              print(f'  - {tf.name} ({size} bytes)')
              if size == 0:
                  print(f'‚ùå Empty trace file: {tf}')
                  sys.exit(1)

          print('‚úÖ All trace files validated successfully')
          "

      - name: Run trace replay tests
        run: |
          echo "üß™ Running trace replay tests with retry logic..."
          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"
            if python -m pytest -q tests/test_trace_replay.py \
                           --junitxml=test_output/pytest_results.xml \
                           --tb=short \
                           -x; then
              echo "‚úÖ Tests passed on attempt $((RETRY_COUNT + 1))"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚ùå Tests failed, retrying in 5 seconds..."
                sleep 5
              else
                echo "‚ùå Tests failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
        # Let pytest exit non-zero to fail the job when tests fail

      - name: Run enhanced trace replay on key traces (reports)
        run: |
          echo "üîÑ Running enhanced trace replay with server process management..."
          # Start mock server in background for network operations
          python examples/network_simulator.py --port 2323 &
          SERVER_PID=$!

          # Give server time to start
          sleep 2

          # Function to cleanup server
          cleanup() {
            echo "üßπ Cleaning up server process..."
            kill $SERVER_PID 2>/dev/null || true
            wait $SERVER_PID 2>/dev/null || true
          }
          trap cleanup EXIT

          # Check if server is running
          if ! ps -p $SERVER_PID > /dev/null; then
            echo "‚ùå Server failed to start"
            exit 1
          fi

          echo "‚úÖ Server started successfully (PID: $SERVER_PID)"

          # Run trace replays with retry logic
          MAX_RETRIES=3
          for trace_file in tests/data/traces/login.trc tests/data/traces/smoke.trc; do
            expected_file="tests/data/expected/$(basename $trace_file .trc)_expected.json"
            output_file="test_output/$(basename $trace_file .trc)_trace_report.json"

            RETRY_COUNT=0
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              echo "Attempting trace replay for $(basename $trace_file) (attempt $((RETRY_COUNT + 1)))"
              if python tools/enhanced_trace_replay.py "$trace_file" --expected "$expected_file" --json > "$output_file" 2>&1; then
                echo "‚úÖ Trace replay successful for $(basename $trace_file)"
                break
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "‚ùå Trace replay failed, retrying in 3 seconds..."
                  sleep 3
                else
                  echo "‚ùå Trace replay failed after $MAX_RETRIES attempts for $(basename $trace_file)"
                  echo "Output saved to $output_file"
                fi
              fi
            done
          done

          # Cleanup will happen via trap
        # Replay tools may return non-zero for failures; we still capture reports

      - name: Upload CI artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trace-replay-test-output-${{ matrix.python-version }}
          path: test_output
